---
ðŸ§  NN Design for HANK Model Estimation
---
The architecture involves a **suite of specialized neural networks (NNs)** designed to **decouple** the traditional nested computational loops of structural estimation, turning the two major bottlenecks (model solving and likelihood evaluation) into fast, upfront training processes.

### 1. General NN Structure and Purpose

The general structure employs standard fully connected feed-forward NNs for function approximation.

* **Purpose:** To replace the two slowest steps in the econometrician's problem, $\max_{\Theta} \mathcal{L}(\mathbb{Y}_{1:T} | \Theta)$, with instant approximations.
    1.  **Model Solution:** Replacing the repetitive, slow numerical solver.
    2.  **Likelihood Evaluation:** Replacing the slow, noisy Monte Carlo (MC) filter (e.g., the Particle Filter).

---

### 2. NN-Solution: Extended Policy Functions

The **NN-Solution** component is a set of NNs trained to approximate the model's policy functions (agents' decision rules) and the Deterministic Steady State (DSS). This eliminates the need to run the slow global solver for every new parameter guess $\Theta$.

#### Setup: Extended Policy Functions and Agentâ€™s Heterogeneity

The innovation is treating the model's structural parameters $\Theta$ not as fixed constants, but as additional **input variables** (or "pseudo-state variables") to the policy function NN.

| Component | Standard Notation | NN-Solution Approximation |
| :--- | :--- | :--- |
| **Traditional Policy Function** | $\psi = \psi(\mathbf{s} | \Theta)$ | The policy function is conditional on $\Theta$. |
| **NN-Solution (Extended PF)** | $\hat{\Psi}$ | $\hat{\Psi}(\mathbf{s}, \Theta) \approx \psi(\mathbf{s} | \Theta)$ |
| **DSS Approximation** | $\bar{\mathbf{s}} = \bar{\mathbf{s}}(\Theta)$ | $\hat{\text{DSS}}(\Theta) \approx \bar{\mathbf{s}}(\Theta)$ (A separate, auxiliary NN) |

* **Inputs:** The input vector to the NN for policy functions is the concatenation of the aggregate state vector ($\mathbf{s}$) and the structural parameter vector ($\Theta$).
* **Agent Heterogeneity:** The NNs are designed to handle the high-dimensional individual state variables ($s^i$, e.g., assets, idiosyncratic risk) alongside the low-dimensional aggregate states ($\mathbf{s}$).

#### Training and Final Adjustments

1.  **Data Generation:** The training data is generated **once** by running a traditional, high-precision solver (e.g., Extended Path Method, EPM) over a large, pre-sampled grid of parameter values $\{\Theta_i\}_{i=1}^M$. This upfront work is computationally intense but non-repetitive.
2.  **Training:** The NN $\hat{\Psi}$ is trained to minimize the mean squared error (MSE) between its output and the exact policy functions generated by the solver.
3.  **Final Adjustments:** After the initial training, the NN can be fine-tuned or "re-fitted" to correct for any approximation errors, ensuring that the approximated policies $\hat{\Psi}$ still satisfy the model's equilibrium conditions (e.g., the Euler equation) to a sufficiently high tolerance.

#### Generated Output

The trained **NN-Solution** ($\hat{\Psi}$) provides an instant, numerical approximation of the model's solution for **any** parameter draw $\Theta$ used in the later estimation phase.

---

### 3. NN-Evaluation (aka NN-Particle Filter)

The **NN-Evaluation** component is a separate NN trained to approximate the entire log-likelihood function $\mathcal{L}$. This replaces the slow, repetitive nature of the traditional MC filter.

#### Improvement over MC Filters

* **Traditional MC Filters (Particle Filter):** The standard **Particle Filter** must run thousands of **Monte Carlo (MC) simulations** over $T$ time periods for *every* parameter draw $\Theta_n$ proposed by the estimation algorithm (e.g., RWMH). This is inherently slow and introduces simulation noise.
    $$
    \text{Traditional Likelihood Calculation:} \mathcal{L}(\Theta_n) = \prod_{t=1}^T p(\mathbb{Y}_t | \mathbb{Y}_{1:t-1}, \Theta_n) \approx \text{PF}( \hat{\psi}(\cdot|\Theta_n) )
    $$
* **NN Improvement:** The **NN-Evaluation** bypasses this entire iterative, noisy process. It learns the mapping from the inputs $\Theta$ directly to the final likelihood value $\mathcal{L}$.

#### Input, Training, and Generated Output

* **Input:** The structural parameter vector $\Theta$.
    $$\text{Input to NN-Evaluation is } \Theta$$
* **Training:** The NN $\hat{\mathcal{N}}$ is trained on a dataset $\mathcal{D}_{\mathcal{L}}$ where the likelihood values were pre-computed using the standard Particle Filter. The crucial factor is that the PF used the **fast policies** from the **NN-Solution** component, making the data generation process feasible.
    $$\text{Training Data: } \mathcal{D}_{\mathcal{L}} = \{(\Theta_i, \mathcal{L}(\mathbb{Y}_{1:T} | \Theta_i))\}_{i=1}^M$$
* **NN-Evaluation Function:** The NN is trained to approximate the log-likelihood function:
    $$\hat{\mathcal{N}}(\Theta) \approx \log \mathcal{L}(\mathbb{Y}_{1:T} | \Theta)$$

#### Final Comments

The primary benefit is that the trained **NN-Evaluation** provides a **fast** and, importantly, **smooth** approximation of the likelihood surface. This smoothness is essential for the stability and efficiency of optimization and sampling algorithms (like RWMH), which otherwise struggle with the noise inherent in MC-based likelihood estimates. During estimation (Phase 2), the likelihood value for any $\Theta_n$ is retrieved **almost instantaneously** by a single feed-forward pass through $\hat{\mathcal{N}}$.